{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à `Scikit-learn`\n",
    "\n",
    "Dans ce notebook, il est question de fournir une introduction à la bibliothèque populaire d'apprentissage automatique `Scikit-learn` qui fournit de nombreux modèles prêts à l'emploi pour faire de l'apprenstissage automatique tout en rendant souple le processus de création de combinaison de plusieurs modèles. \n",
    "\n",
    "En résumé, l'apprensitssage automatique (Machine learning : ML) vise à construire une fonction $f$ qui étant donné un vecteur de **caractéristiques (features en anglais)** $X$, de contruire un lien avec la sortie $y$ encore appelé **étiquete (label en anglais)**, en d'autres termes le ML chercher une fonction $f$ tel que $f(X) \\approx y$. Lorsque $y$ est connu, on parle **d'apprensitssage supervisé** et lorsque $y$ est inconnu, on parle **d'apprensitasse non supervisé**. La fonction $f$ est le modèle que l'on cherche à établir. Il existe plusieurs modèles en fonction du type de problèmes et même des données que l'on dispose. Il y'a tout d'abord souvent une phase dite **d'apprentissage** pendant laquel le modèle est constuit avec un sous-ensemble de données (avec étiquete, on parle de données étiquetées) issu des données initiales et une phase dite de **test** où le modèle consruit est testé avec un autre sous-ensemble de données.\n",
    "\n",
    "Pour cet exemple introducif sur `scikit-learn`, nous allons travailler avec des données sur le prix médian des maisons (regroupées par groupes) dans l'état de Californie aux états unis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -3] Temporary failure in name resolution>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    919\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4007/3969049472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# On télécharge les données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/datasets/_california_housing.py\u001b[0m in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0marchive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m     \u001b[0mchecksum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    543\u001b[0m                                   '_open', req)\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1398\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -3] Temporary failure in name resolution>"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# On télécharge les données\n",
    "data = fetch_california_housing()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "print(data['DESCR']) # Description du jeu de données (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revanche, chaque modèle possède ses propres paramètres souvent appelés **hyper-paramètres**. `Scikit-learn` les utilise dans le processus d'apprentissage pour calibrer le modèle par rapport au problème en face. Dans l'exemple suivant, on a crée le modèle de regression de **Ridge** qui est un type de regression multiple avec un **hyper-paramètre**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "ridge = Ridge(alpha=0.1) # alpha est un hyperparamètre initialisé à 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la bibliothèque `scikit-learn`, chaque modèle de ML est vu comme une classe à part entière avec ses propres **hyper-paramètres** le plus souvent avec des bonnes valeurs par défauts. ils sont appelés des **estimateurs** (**estimators**), il en existe **trois** types : **classifieurs (classifiers), regresseurs (regressors), et transformateurs (transformers)** tous héritant de la classe estimateur de base dénomée `BaseEstimator`. En plus de cette classe de Base, chaque type d'estimateur hérite d'une autre classe selon son type, c'est-à-dire soit `RegressorMixin` (pour un regresseur) soit `ClassifierMixin` (pour un classifieur) soit `TransformerMixin` (pour un transformateur). Ainsi si on souhaite écrire un nouveau modèle il faudra créer une classe qui hérite de `BaseEstimator` et de la classe basique correspondante par exemple `RegressorMixin` si on souhaite écrire un nouveau regresseur.\n",
    "\n",
    "Tous les estimateurs (algorithmes d'apprenstissage) peuvent être classés en deux groupes : \n",
    "\n",
    "1. **Prédicteurs (predictors)**\n",
    "2. **Transformateurs (transformers)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédicteurs : classifieurs et regresseurs\n",
    "\n",
    "Comme leurs noms l'indiquent, ils vont faire de la prédiction, soit de la classification (dans ce cas, le label n'est pas un réel) ou de la régression (le label est un réel). Ces classes possèdent deux méthodes principales : \n",
    "\n",
    "* `fit(X, y)`: entraine ou ajuste l'objet (ici le modèle) à la matrice de caractéristiques $X$ et le label $y$.\n",
    "* `predict(X)`: fait des prédictions sur l'ensemble des données passées $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.13164983 3.97660644 3.67657094 ... 0.17125141 0.31910524 0.51580363]\n",
      "Dimension du tableau de prédiction: (20640,)\n",
      "Dimension de l'ensemble d'apprensissage: (20640, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # Importation du modèle de regression linéaire\n",
    "\n",
    "# On crée le modèle et l'entraine/ajuste\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# On prédit les étiquetes des caractéristiques X\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(y_pred)\n",
    "print(\"Dimension du tableau de prédiction: {}\".format(y_pred.shape))\n",
    "print(\"Dimension de l'ensemble d'apprensissage: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que dans ce cas, nous avons un vecteur des caractéristiques de taille $8$, et nous utilisons le modèle regression linéaire, alors le modèle s'écrit  de la façon suivante : \n",
    "$$ y(X) = \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\beta_5 x_5 + \\beta_6 x_6 + \\beta_7 x_7 + \\beta_8 x_8 + \\beta_0. $$\n",
    "\n",
    "Après apprensissage (ajustement), `scikit-learn` stocke les coefficients dans des **attributs spécifiques** du modèle avec un _underscore_, et on peut les recupérer dans les attributs `coefs_` et `intercept_` du modèle (voir aide sur le modèle de regression linéaire `LinearRegression`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β_0: -36.941920207184516\n",
      "β_1: 0.4366932931343246\n",
      "β_2: 0.009435778033238069\n",
      "β_3: -0.10732204139090418\n",
      "β_4: 0.6450656935198134\n",
      "β_5: -3.976389421207444e-06\n",
      "β_6: -0.00378654265497081\n",
      "β_7: -0.42131437752714374\n",
      "β_8: -0.43451375467477804\n"
     ]
    }
   ],
   "source": [
    "# Ici, on peut consulter les hyper-paramètres de ce modèle.\n",
    "print(\"β_0: {}\".format(model.intercept_)) \n",
    "\n",
    "for i in range(8):\n",
    "    print(\"β_{}: {}\".format(i+1, model.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est souhaitable de savoir si oui ou non le modèle prédit bien, nous pouvons faire appel à la méthode `score(X, y)` dont hérite par défaut tout prédciteur, elle fonctionne en deux étapes : \n",
    "1. Elle exécute en premier la méthode `predict(X)` pour déterminer les valeurs prédites de $X$ par le modèle\n",
    "2. Utilise ces valeurs prédites pour évaluer le modèle par rapport aux valeurs ($y$) qui lui sont passées en paramètres.\n",
    "\n",
    "Il faut savoir que cette évaluation est fonction du type de modèle soit une regression ou une classification. Pour une regression, c'est la valeur du $R^2$ qui est utilisé et pour une classification, c'est la précision. le R-carré ou $R^2$ est utilisé en statistique pour juger de la qualité d'une regression linéaire.\n",
    "\n",
    "Pour $n$ valeurs à prédire $\\hat y_i, i=1\\cdots n$ de $y_i$, $R^2$ est défini par : \n",
    "$$R^2 = 1-\\dfrac{\\sum_{i=1}^n\\left(y_i-\\hat{y_i}\\right)^2}{\\sum_{i=1}^n\\left(y_i-\\bar y\\right)^2}$$\n",
    "\n",
    "On peut tout aussi utiliser d'autres métriques comme le **Root Mean Square Error (RMSE)** défini par : \n",
    "**RMSE** = $\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\,(y_i - \\hat y^i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.606233\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2: {:g}\".format(model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur du score nous donne un indice pour savoir si on peut faire appel à d'autres types de modèles plus adaptés à la situation . Mais avant de les utiliser, il faut les connaitre, et savoir leurs limites surtout en terme de temps de calcul, il est toutefois possible de combiner plusieurs modèles. \n",
    "\n",
    "Voici un exemple de modèle plus adapté à cette situation que la regression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.26432728 3.87864519 3.92074556 ... 0.63664692 0.74759279 0.7994969 ]\n",
      "R^2: 0.803324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor # Regression linéaire utilisant la descente du gradient\n",
    "\n",
    "# On crée le modèle et l'entraine/ajuste\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# On prédit les étiquetes des caractéristiques X\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(y_pred)\n",
    "print(\"R^2: {:g}\".format(model.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle est bien meilleur que la regression simple dans ce cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformateurs\n",
    "\n",
    "Ce sont des modèles qui agissent sur les données dans le but de les transformer pour usage ultérieur. Ils sont très utiles par exemple pour mettre à l'échelle un ensemble de données car certains algoruthmes de ML ne fonctionnent correctement que lorsque les données sont mises à l'échelle, par exemple centrées, c'est le cas des technique d'analyse comme **l'analyse en composante principale (ACP)**. Les modèles dans cette classe implémentent les interfaces suivantes : \n",
    "\n",
    "* `fit(X)`: entraine ou ajuste l'objet (le modèle) à la matrice de caractéristiques $X$.\n",
    "* `transform(X)`: applique une transformation sur la matrice de caractéristiques $X$ en utilisant tous les paramètres appris\n",
    "* `fit_transform(X)`: applique la méthode `fit(X)` ensuite `transform(X)`.\n",
    "\n",
    "`StandardScaler` est un transformateur qui permet de centrer les données de manière à avoir une moyenne $0$ et une variance égale à $1$. Formelleemnt, il transforme la cractéristique $x_i$ en $x'_i$ de la manière suivante : \n",
    "\n",
    "$$ x'_i = \\frac{x_i - \\mu_i}{\\sigma_i}. $$\n",
    "\n",
    "On peut par exemple l'utiliser pour mettre à l'échelle les données des prix des maisons qu'on a chargé plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moyenne non à l'échelle</th>\n",
       "      <th>variance non à l'échelle</th>\n",
       "      <th>moyenne à l'échelle</th>\n",
       "      <th>variance à l'échelle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>3.609148e+00</td>\n",
       "      <td>6.609700e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>28.639486</td>\n",
       "      <td>1.583886e+02</td>\n",
       "      <td>5.508083e-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>5.429000</td>\n",
       "      <td>6.121236e+00</td>\n",
       "      <td>6.609700e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>1.096675</td>\n",
       "      <td>2.245806e-01</td>\n",
       "      <td>-1.060306e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1.282408e+06</td>\n",
       "      <td>-1.101617e-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>3.070655</td>\n",
       "      <td>1.078648e+02</td>\n",
       "      <td>3.442552e-18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>35.631861</td>\n",
       "      <td>4.562072e+00</td>\n",
       "      <td>-1.079584e-15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>4.013945e+00</td>\n",
       "      <td>-8.526513e-15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            moyenne non à l'échelle  variance non à l'échelle  \\\n",
       "MedInc                     3.870671              3.609148e+00   \n",
       "HouseAge                  28.639486              1.583886e+02   \n",
       "AveRooms                   5.429000              6.121236e+00   \n",
       "AveBedrms                  1.096675              2.245806e-01   \n",
       "Population              1425.476744              1.282408e+06   \n",
       "AveOccup                   3.070655              1.078648e+02   \n",
       "Latitude                  35.631861              4.562072e+00   \n",
       "Longitude               -119.569704              4.013945e+00   \n",
       "\n",
       "            moyenne à l'échelle  variance à l'échelle  \n",
       "MedInc             6.609700e-17                   1.0  \n",
       "HouseAge           5.508083e-18                   1.0  \n",
       "AveRooms           6.609700e-17                   1.0  \n",
       "AveBedrms         -1.060306e-16                   1.0  \n",
       "Population        -1.101617e-17                   1.0  \n",
       "AveOccup           3.442552e-18                   1.0  \n",
       "Latitude          -1.079584e-15                   1.0  \n",
       "Longitude         -8.526513e-15                   1.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# On crée et ajuste le transformateur\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# On met à l'échelle les données\n",
    "Xt = scaler.transform(X)\n",
    "\n",
    "# On crée un data frame des résultats\n",
    "stats = np.vstack((X.mean(axis=0), X.var(axis=0), Xt.mean(axis=0), Xt.var(axis=0))).T\n",
    "feature_names = data['feature_names']\n",
    "columns = ['moyenne non à l\\'échelle', 'variance non à l\\'échelle', 'moyenne à l\\'échelle',\n",
    "           'variance à l\\'échelle']\n",
    "\n",
    "df = pd.DataFrame(stats, index=feature_names, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformateur Colonne\n",
    "\n",
    "Les caractéristiques sont souvent de divers types, numériques, catégorielle et même textuelles et pour chaque type de caractéristiques, on applique un transformateur distinct. Le transformateur [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) de `scikit-learn` permet d'appliquer un transformateur par colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne MedInc avant transformation? 3.8706710029069766\n",
      "Moyenne MedInc après transformation? 6.609699867535816e-17 \n",
      "\n",
      "Moyenne Longitude avant transformation? -119.56970445736432\n",
      "Moyenne Longitude après transformation? -119.56970445736432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    remainder='passthrough', # On ne transforme pas les autres colonnes (Latitude et Longitude). 'drop' supprime\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), slice(0,6)) # les 6 première colonnes\n",
    "    ]\n",
    ")\n",
    "\n",
    "col_transformer.fit(X)\n",
    "Xt = col_transformer.transform(X)\n",
    "\n",
    "print('Moyenne MedInc avant transformation?', X.mean(axis=0)[0])\n",
    "print('Moyenne MedInc après transformation?', Xt.mean(axis=0)[0], '\\n')\n",
    "\n",
    "print('Moyenne Longitude avant transformation?', X.mean(axis=0)[-1])\n",
    "print('Moyenne Longitude après transformation?', Xt.mean(axis=0)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant permet de supprimer la colonne à l'indice $0$ `'MedInc'`. Celà arrive par exemple lorsque la colonne présente des données corrompues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de caractéristiques dans X: 8\n",
      "Nombre de caractéristiques dans Xt: 7\n"
     ]
    }
   ],
   "source": [
    "col_transformer = ColumnTransformer(\n",
    "    remainder='passthrough',\n",
    "    transformers=[\n",
    "        ('remove', 'drop', 0), # On supprime la première colonne\n",
    "        ('scaler', StandardScaler(), slice(1,6)) # On applique la transformation sur le vecteur les colonnes 1 à 6\n",
    "    ]\n",
    ")\n",
    "\n",
    "Xt = col_transformer.fit_transform(X)\n",
    "\n",
    "print('Nombre de caractéristiques dans X:', X.shape[1])\n",
    "print('Nombre de caractéristiques dans Xt:', Xt.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Il arrive que l'on soit amener à construire un mélange de modèles pour aboutir à un modèle plus complexe et plus amélioré quoique parfois coûteux en terme de temps d'apprenstissage et même de prévision. `Scikit-learn` réalise celà grace à la classe `Pipeline` qui est un estimateur caractérisé par une succession de transformateurs avec au final un estimateur.\n",
    "Dans l'exemple qui suit, on va : \n",
    "\n",
    "1. Mettre à l'échelle le jeu de données.\n",
    "1. Ajouter des caractéristiques polynomiales.\n",
    "1. Entrainer un modèle linéaire de regression avec le jeu transformé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# on construit le pipeline\n",
    "scaler = StandardScaler()\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('poly', poly_features),\n",
    "    ('regressor', lin_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False),\n",
       " 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "          normalize=False)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps # Dictonnaire donnant la liste des transformateurs et estimateurs du pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque nous faisons `pipe.fit(X, y)`, l'ensemble des instruction exécutées est le suivant : \n",
    "```\n",
    "Xt = scaler.fit_transform(X) \n",
    "Xt = poly.fit_transform(Xt)\n",
    "lin_reg.fit(Xt,y)\n",
    "```\n",
    "Et lorsqu'on exécute `pipe.predict(X, y)`, l'ensemble des données `X` va passer par tous les transformateurs et à la fin le prédicteur.\n",
    "```\n",
    "Xt = scaler.transform(X)\n",
    "Xt = poly.transform(Xt)\n",
    "y_pred = lin_reg.predict(Xt)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.00298901 3.92349228 3.99012926 ... 0.83369975 0.88801566 0.97559649]\n",
      "R^2: 0.6832976293317492\n"
     ]
    }
   ],
   "source": [
    "# Entraine/ajuste le modèle et prédit les étiquetes\n",
    "pipe.fit(X, y)\n",
    "y_pred = pipe.predict(X)\n",
    "\n",
    "print(y_pred)\n",
    "print(\"R^2: {}\".format(pipe.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union de caractéristiques (Feature Union)\n",
    "\n",
    "De même qu'il soit capable de combiner plusieurs estimateurs, il est aussi possible de combiner plusieurs transformateurs. `ColumnTransformer` agit sur des colonnes séparemment, mais est limité lorsqu'on souhaite appliquer plusieurs transformateurs sur une colonne précise. `Scikit-learn` fourni la classe `FeatureUnion` qui permet de combiner un ensemble de transformateurs. Il les exécutent en parallèle pour avoir en sortie une seule matrice de données transformées. Avec celà, `scikit-learn` permet de construire des modèles de ML plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour illustrer le déroulé de `FeatureUnion`, nous allons appliquer deux transformateurs en parallèle afin de produire des nouvelles données qui seront ensuite passées à un modèle de regression linéaire. La méthdode ACP permet une méthode d'analyse de données qui permet la réduction de la dimension des données de grandes tailles (plusieurs caractéristiques)souvent correlées pour produire de nouvelles caractéristiques qui cette-fois seront non correllées. Elle vise à extraire parmis les caractéristiques $X$, celles qui sont les plus importantes pour générer tous les individus. Cette méthode fonctionne bien lorsque les données sont mises à l'échelle. La fonction `PCA` de la bibliothèque permet de la mettre en exergue.\n",
    "\n",
    "`SelectKBest` renvoie les $k$ meilleurs caractéristiques qui vérifient un certain critère. Par exemple, on peut rechercher les $3$ meilleurs caractéristiques fortement correlées avec l'étiquete (label). `VarianceThreshold` renvoie les caractéristiques qui ont une variance supérieure à un seuil fixé, on va donc combiner les deux transformateurs pour créer un nouveau jeu de caractéristiques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de colonne/caractéristique dans le jeu originel: 8\n",
      "nombre de colonne/caractéristique dans le nouveau jeu: 10\n",
      "R^2: 0.5961995839710024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "selector = SelectKBest(f_regression, k=3)\n",
    "var_sel = VarianceThreshold(threshold = 1)\n",
    "\n",
    "union = FeatureUnion([('var_sel', var_sel), ('selector', selector)])\n",
    "pipe = Pipeline([('union', union), ('regressor', lin_reg)])\n",
    "pipe.fit(X, y)\n",
    "\n",
    "print(\"nombre de colonne/caractéristique dans le jeu originel: {}\".format(X.shape[-1]))\n",
    "print(\"nombre de colonne/caractéristique dans le nouveau jeu: {}\".format(union.transform(X).shape[-1]))\n",
    "print(\"R^2: {}\".format(pipe.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc au final 10 variables dont $3$ ont une meilleure correlation avec la label, ça veut dire que `VarianceThreshold` a éliminé une variable et produit $7$."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
