{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chargemennt de la dataset spam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spams = pd.read_csv(\"./spam.csv\", header = 0, encoding = 'ISO-8859-14', sep = ',' )\n",
    "spams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppression des colonnes vides et renommage des noms de colonnes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spams = spams[['v1', 'v2']]\n",
    "spams.columns = ['class', 'text']\n",
    "spams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`codage one hot`\n",
    "\n",
    "Vue pour utilisee la classification bayesienne, il est imperatif de transformer les textes de mail en des vecteurs numeriques leurs representant en s'appuyant sur l'ensemble des mots contenu dans ces derniers (appelé vocabulaire). \n",
    "\n",
    "Il existe plusieurs moyens de representation de texte, à l'instar du codage one hot dont le principe est : \" de part un mot du vocabulaire, si dans le texte ce mot est utilise on mettra `1` dans la position du vecteur correspondant a ce mot et `0` sinon \".\n",
    "\n",
    "pour le faire dans notre cas, nous avons choisi d'utiliser la classe `CountVectorizer` du module `sklearn.feature_extraction.text`, dont la particularité est qu'elle permet de conserver apres transformation des textes la matrice obtenu dans un objet de type `space matrix` permettant de mieux reduire la taille des donnees de la matrice en memoire lorsqu'il y'a grandement de valeur `0` inutile dans notre contexte \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimension :  (5572, 8681)\n",
      " valeur de notre objet obtenu :    (0, 3550)\t1\n",
      "  (0, 8029)\t1\n",
      "  (0, 4350)\t1\n",
      "  (0, 5920)\t1\n",
      "  (0, 2327)\t1\n",
      "  (0, 1303)\t1\n",
      "  (0, 5537)\t1\n",
      "  (0, 4087)\t1\n",
      "  (0, 1751)\t1\n",
      "  (0, 3634)\t1\n",
      "  (0, 8488)\t1\n",
      "  (0, 4476)\t1\n",
      "  (0, 1749)\t1\n",
      "  (0, 2048)\t1\n",
      "  (0, 7645)\t1\n",
      "  (0, 3594)\t1\n",
      "  (0, 1069)\t1\n",
      "  (0, 8266)\t1\n",
      "  (1, 5504)\t1\n",
      "  (1, 4512)\t1\n",
      "  (1, 4318)\t1\n",
      "  (1, 8391)\t1\n",
      "  (1, 5533)\t1\n",
      "  (2, 4087)\t1\n",
      "  (2, 3358)\t1\n",
      "  :\t:\n",
      "  (5570, 4218)\t1\n",
      "  (5570, 8312)\t1\n",
      "  (5570, 1084)\t1\n",
      "  (5570, 4615)\t1\n",
      "  (5570, 7039)\t1\n",
      "  (5570, 3308)\t1\n",
      "  (5570, 7627)\t1\n",
      "  (5570, 1438)\t1\n",
      "  (5570, 5334)\t1\n",
      "  (5570, 2592)\t1\n",
      "  (5570, 8064)\t1\n",
      "  (5570, 1778)\t1\n",
      "  (5570, 7049)\t1\n",
      "  (5570, 2892)\t1\n",
      "  (5570, 3470)\t1\n",
      "  (5570, 1786)\t1\n",
      "  (5570, 3687)\t1\n",
      "  (5570, 4161)\t1\n",
      "  (5570, 903)\t1\n",
      "  (5570, 1546)\t1\n",
      "  (5571, 7756)\t1\n",
      "  (5571, 5244)\t1\n",
      "  (5571, 4225)\t2\n",
      "  (5571, 7885)\t1\n",
      "  (5571, 6505)\t1\n",
      " matrice y contenu : \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "\n",
    "# on instancie le converteur de donnees texte de sklearn\n",
    "data_converter = CountVectorizer()\n",
    "\n",
    "# on realise la conversion\n",
    "spams_one_hot = data_converter.fit_transform(spams.text)\n",
    "\n",
    "print(\" dimension : \", spams_one_hot.shape)\n",
    "print(\" valeur de notre objet obtenu : \", spams_one_hot)\n",
    "print(\" matrice y contenu : \\n\", spams_one_hot.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la nous avons bien une \"sparse matrix\" contenant une matrice de 5572 lignes (qui est le nombre d'observation) et de 8681 colonnes (qui est le nombre de mots du vocabulaire). nous pouvons aussi nous rendre compte que cette matrice contient enormement de 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il faut noter qu'avoir un vocabulaire de 8681 mots est enorme et peut grandement impacter les performances de l'algorithme d'entrainement et donc il faudra minimiser le nombre de mots. \n",
    "\n",
    "Pour le faire nous pouvons:\n",
    "\n",
    "        - mettre tous les mots en miniscules \n",
    "fait par defaut lors de la conversion avec CountVectorizer\n",
    "                        \n",
    "        - recuperer uniquement les racines des mots \n",
    "fait par defaut grace au l'expression reguliere par defaut `r\"(?u)\\b\\w\\w+\\b\"`)\n",
    "    \n",
    "        - supprimer les mots d'utilité courante (par exemple 'il' , 'nous', ... etc) qui ont une forte probablite d'utilisation (frequence)\n",
    "egalement fait par defaut, cette frequence d'apparition est considere compris entre [0.7 .. 1]\n",
    "    \n",
    "        - donner un nombre de mots maximales\n",
    "induira forcement une baisse de performance du model\n",
    "\n",
    "Pour ce tutoriel nous definirons un nombre maximum de mots a 3000 (choix preferentiel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimension :  (5572, 3000)\n"
     ]
    }
   ],
   "source": [
    "# on instancie le converteur de donnees texte de sklearn\n",
    "data_converter = CountVectorizer(max_features=3000)\n",
    "\n",
    "# on realise la conversion\n",
    "spams_one_hot = data_converter.fit_transform(spams.text)\n",
    "\n",
    "print(\" dimension : \", spams_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phase d'entrainement et evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoupage en partie de test et d'apprentissage homogene des donnes pretraitees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data, labels = spams_one_hot.toarray(), spams['class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, labels, train_size=0.8, test_size=0.2, stratify= labels, random_state = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import  BernoulliNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction et evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115,)\n",
      "(1115,)\n",
      "matrice de confusion :\n",
      " [[964   2]\n",
      " [ 14 135]]\n",
      "exactitude : 0.9856502242152466\n",
      "precision : 0.9855432657143284\n",
      "rappel : 0.9519849375408174\n",
      "f-mesure : 0.968473483563818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(predictions.shape)\n",
    "\n",
    "def exactitude(m):\n",
    "    result= 0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]\n",
    "    return result/(sum(sum(m)))\n",
    "    \n",
    "def precision(m):\n",
    "    result=0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]/sum(m[:,i])\n",
    "    return result/2   \n",
    "    \n",
    "def rappel(m):\n",
    "    result=0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]/sum(m[i,:])\n",
    "    return result/2 \n",
    "def f_mesure(m):\n",
    "    r=p=0\n",
    "    for i in range(m.shape[0]):\n",
    "        r += m[i,i]/sum(m[i,:])\n",
    "        p += m[i,i]/sum(m[:,i])\n",
    "    r/=2\n",
    "    p/=2\n",
    "    return 2*r*p/(r+p) \n",
    "\n",
    "matrice_confusion = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "print(\"matrice de confusion :\\n\" ,matrice_confusion)\n",
    "print(\"exactitude :\", exactitude(matrice_confusion))\n",
    "print(\"precision :\", precision(matrice_confusion))\n",
    "print(\"rappel :\", rappel(matrice_confusion))\n",
    "print(\"f-mesure :\", f_mesure(matrice_confusion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "malgres les valeurs de mettriques obtenu, il fautt noter que cette evaluation est basée sur les predictions faites sur les donnees de test pretraitées en meme temps que ceux de l'entrainnement.\n",
    "Ainsi pour avoir la certitude que le modele est si bon, on pourrait reprétraiter les données et les utilises pour les tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(5572,)\n",
      "matrice de confusion :\n",
      " [[4815   10]\n",
      " [  63  684]]\n",
      "exactitude : 0.9868987796123474\n",
      "precision : 0.9863378244733456\n",
      "rappel : 0.956795055871153\n",
      "f-mesure : 0.971341860786683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# repretraitement des donnees\n",
    "spams_one_hot = data_converter.transform(spams.text)\n",
    "data, labels = spams_one_hot.toarray(), spams['class'].values\n",
    "\n",
    "#predictions\n",
    "predictions = model.predict(data)\n",
    "\n",
    "print(labels.shape)\n",
    "print(predictions.shape)\n",
    "\n",
    "def exactitude(m):\n",
    "    result= 0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]\n",
    "    return result/(sum(sum(m)))\n",
    "    \n",
    "def precision(m):\n",
    "    result=0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]/sum(m[:,i])\n",
    "    return result/2   \n",
    "    \n",
    "def rappel(m):\n",
    "    result=0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]/sum(m[i,:])\n",
    "    return result/2 \n",
    "def f_mesure(m):\n",
    "    r=p=0\n",
    "    for i in range(m.shape[0]):\n",
    "        r += m[i,i]/sum(m[i,:])\n",
    "        p += m[i,i]/sum(m[:,i])\n",
    "    r/=2\n",
    "    p/=2\n",
    "    return 2*r*p/(r+p) \n",
    "\n",
    "matrice_confusion = confusion_matrix(y_true=labels, y_pred=predictions)\n",
    "print(\"matrice de confusion :\\n\" ,matrice_confusion)\n",
    "print(\"exactitude :\", exactitude(matrice_confusion))\n",
    "print(\"precision :\", precision(matrice_confusion))\n",
    "print(\"rappel :\", rappel(matrice_confusion))\n",
    "print(\"f-mesure :\", f_mesure(matrice_confusion))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03d85422f651b7f3b8cfc404434b17496a20a36d5d6a328a4d5b29f706a68093"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
