{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chargemennt de la dataset spam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nI_1vduIRgL"
      },
      "source": [
        "## chargemennt de la dataset spam.csv"
      ]
    },
>>>>>>> e870ab0989bef8a31a4267cbe9b21b7c18bf694c
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi3jtTrXJwXg",
        "outputId": "514813df-a87d-4d02-e6ba-9cda54774910"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
<<<<<<< HEAD
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spams = pd.read_csv(\"./spam.csv\", header = 0, encoding = 'ISO-8859-14', sep = ',' )\n",
    "spams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppression des colonnes vides et renommage des noms de colonnes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
=======
    },
>>>>>>> e870ab0989bef8a31a4267cbe9b21b7c18bf694c
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zEgRl3p6IRgQ",
        "outputId": "86bb953e-bb57-4dcd-956c-48d27c1ea1ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        v1                                                 v2 Unnamed: 2  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "...    ...                                                ...        ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
              "5571   ham                         Rofl. Its true to its name        NaN   \n",
              "\n",
              "     Unnamed: 3 Unnamed: 4  \n",
              "0           NaN        NaN  \n",
              "1           NaN        NaN  \n",
              "2           NaN        NaN  \n",
              "3           NaN        NaN  \n",
              "4           NaN        NaN  \n",
              "...         ...        ...  \n",
              "5567        NaN        NaN  \n",
              "5568        NaN        NaN  \n",
              "5569        NaN        NaN  \n",
              "5570        NaN        NaN  \n",
              "5571        NaN        NaN  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d74ff26-db7e-4952-b131-b0980068aab4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d74ff26-db7e-4952-b131-b0980068aab4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d74ff26-db7e-4952-b131-b0980068aab4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d74ff26-db7e-4952-b131-b0980068aab4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "spams = pd.read_csv(\"./drive/MyDrive/GitHub/spam.csv\", header = 0, encoding = 'ISO-8859-14', sep = ',' )\n",
        "spams"
      ]
<<<<<<< HEAD
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spams = spams[['v1', 'v2']]\n",
    "spams.columns = ['class', 'text']\n",
    "spams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`codage one hot`\n",
    "\n",
    "Vue pour utilisee la classification bayesienne, il est imperatif de transformer les textes de mail en des vecteurs numeriques leurs representant en s'appuyant sur l'ensemble des mots contenu dans ces derniers (appelé vocabulaire). \n",
    "\n",
    "Il existe plusieurs moyens de representation de texte, à l'instar du codage one hot dont le principe est : \" de part un mot du vocabulaire, si dans le texte ce mot est utilise on mettra `1` dans la position du vecteur correspondant a ce mot et `0` sinon \".\n",
    "\n",
    "pour le faire dans notre cas, nous avons choisi d'utiliser la classe `CountVectorizer` du module `sklearn.feature_extraction.text`, dont la particularité est qu'elle permet de conserver apres transformation des textes la matrice obtenu dans un objet de type `space matrix` permettant de mieux reduire la taille des donnees de la matrice en memoire lorsqu'il y'a grandement de valeur `0` inutile dans notre contexte \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimension :  (5572, 8681)\n",
      " valeur de notre objet obtenu : \n",
      "   (0, 3550)\t1\n",
      "  (0, 8029)\t1\n",
      "  (0, 4350)\t1\n",
      "  (0, 5920)\t1\n",
      "  (0, 2327)\t1\n",
      "  (0, 1303)\t1\n",
      "  (0, 5537)\t1\n",
      "  (0, 4087)\t1\n",
      "  (0, 1751)\t1\n",
      "  (0, 3634)\t1\n",
      "  (0, 8488)\t1\n",
      "  (0, 4476)\t1\n",
      "  (0, 1749)\t1\n",
      "  (0, 2048)\t1\n",
      "  (0, 7645)\t1\n",
      "  (0, 3594)\t1\n",
      "  (0, 1069)\t1\n",
      "  (0, 8266)\t1\n",
      "  (1, 5504)\t1\n",
      "  (1, 4512)\t1\n",
      "  (1, 4318)\t1\n",
      "  (1, 8391)\t1\n",
      "  (1, 5533)\t1\n",
      "  (2, 4087)\t1\n",
      "  (2, 3358)\t1\n",
      "  :\t:\n",
      "  (5570, 4218)\t1\n",
      "  (5570, 8312)\t1\n",
      "  (5570, 1084)\t1\n",
      "  (5570, 4615)\t1\n",
      "  (5570, 7039)\t1\n",
      "  (5570, 3308)\t1\n",
      "  (5570, 7627)\t1\n",
      "  (5570, 1438)\t1\n",
      "  (5570, 5334)\t1\n",
      "  (5570, 2592)\t1\n",
      "  (5570, 8064)\t1\n",
      "  (5570, 1778)\t1\n",
      "  (5570, 7049)\t1\n",
      "  (5570, 2892)\t1\n",
      "  (5570, 3470)\t1\n",
      "  (5570, 1786)\t1\n",
      "  (5570, 3687)\t1\n",
      "  (5570, 4161)\t1\n",
      "  (5570, 903)\t1\n",
      "  (5570, 1546)\t1\n",
      "  (5571, 7756)\t1\n",
      "  (5571, 5244)\t1\n",
      "  (5571, 4225)\t2\n",
      "  (5571, 7885)\t1\n",
      "  (5571, 6505)\t1\n",
      " matrice y contenu : \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "\n",
    "# on instancie le converteur de donnees texte de sklearn\n",
    "data_converter = CountVectorizer()\n",
    "\n",
    "# on realise la conversion\n",
    "spams_one_hot = data_converter.fit_transform(spams.text)\n",
    "\n",
    "print(\" dimension : \", spams_one_hot.shape)\n",
    "print(\" valeur de notre objet obtenu : \\n\", spams_one_hot)\n",
    "print(\" matrice y contenu : \\n\", spams_one_hot.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la nous avons bien une \"sparse matrix\" contenant une matrice de 5572 lignes (qui est le nombre d'observation) et de 8681 colonnes (qui est le nombre de mots du vocabulaire). nous pouvons aussi nous rendre compte que cette matrice contient enormement de 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il faut noter qu'avoir un vocabulaire de 8681 mots est enorme et peut grandement impacter les performances de l'algorithme d'entrainement et donc il faudra minimiser le nombre de mots. \n",
    "\n",
    "Pour le faire nous pouvons:\n",
    "\n",
    "        - mettre tous les mots en miniscules \n",
    "fait par defaut lors de la conversion avec CountVectorizer\n",
    "                        \n",
    "        - recuperer uniquement les racines des mots \n",
    "fait par defaut grace au l'expression reguliere par defaut `r\"(?u)\\b\\w\\w+\\b\"`)\n",
    "    \n",
    "        - supprimer les mots d'utilité courante (par exemple 'il' , 'nous', ... etc) qui ont une forte probablite d'utilisation (frequence)\n",
    "egalement fait par defaut, cette frequence d'apparition est considere compris entre [0.7 .. 1]\n",
    "    \n",
    "        - donner un nombre de mots maximales\n",
    "induira forcement une baisse de performance du model\n",
    "\n",
    "Pour ce tutoriel nous definirons un nombre maximum de mots a 3000 (choix preferentiel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dimension :  (5572, 3000)\n"
     ]
    }
   ],
   "source": [
    "# on instancie le converteur de donnees texte de sklearn\n",
    "data_converter = CountVectorizer(max_features=3000)\n",
    "\n",
    "# on realise la conversion\n",
    "spams_one_hot = data_converter.fit_transform(spams.text)\n",
    "\n",
    "print(\" dimension : \", spams_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phase d'entrainement et evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoupage en partie de test et d'apprentissage homogene des donnes pretraitees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data, labels = spams_one_hot.toarray(), spams['class'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, labels, train_size=0.8, test_size=0.2, stratify= labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
=======
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDoMVh8JIRgW"
      },
      "source": [
        "## pretraitement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSMOgCRzIRga"
      },
      "source": [
        "suppression des colonnes vides et renommage des noms de colonnes "
      ]
    },
>>>>>>> e870ab0989bef8a31a4267cbe9b21b7c18bf694c
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr5PLflUIRgd",
        "outputId": "ff196a34-0d85-4859-9f94-1e3f1b8ef1b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     class                                               text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham              Will Ì_ b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spams = spams[['v1', 'v2']]\n",
        "spams.columns = ['class', 'text']\n",
        "spams"
      ]
<<<<<<< HEAD
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import  BernoulliNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction et evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115,)\n",
      "(1115,)\n",
      "matrice de confusion :\n",
      " [[965   1]\n",
      " [ 11 138]]\n",
      "exactitude : 0.989237668161435\n",
      "precision : 0.9907676317962024\n",
      "rappel : 0.9625696499784624\n",
      "f-mesure : 0.9764651107069553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(predictions.shape)\n",
    "\n",
    "def exactitude(m):\n",
    "    result= 0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]\n",
    "    return result/(sum(sum(m)))\n",
    "    \n",
    "def precision(m):\n",
    "    result=0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]/sum(m[:,i])\n",
    "    return result/2   \n",
    "    \n",
    "def rappel(m):\n",
    "    result=0\n",
    "    for i in range(m.shape[0]):\n",
    "        result += m[i,i]/sum(m[i,:])\n",
    "    return result/2 \n",
    "def f_mesure(m):\n",
    "    r=p=0\n",
    "    for i in range(m.shape[0]):\n",
    "        r += m[i,i]/sum(m[i,:])\n",
    "        p += m[i,i]/sum(m[:,i])\n",
    "    r/=2\n",
    "    p/=2\n",
    "    return 2*r*p/(r+p) \n",
    "\n",
    "matrice_confusion = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
    "print(\"matrice de confusion :\\n\" ,matrice_confusion)\n",
    "print(\"exactitude :\", exactitude(matrice_confusion))\n",
    "print(\"precision :\", precision(matrice_confusion))\n",
    "print(\"rappel :\", rappel(matrice_confusion))\n",
    "print(\"f-mesure :\", f_mesure(matrice_confusion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modele de bayes (prise en main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrice de confusion :\n",
      " [[964   2]\n",
      " [ 39 110]]\n",
      "exactitude : 0.9632286995515695\n",
      "precision : 0.9716297535963538\n",
      "rappel : 0.8680923200911529\n",
      "f-mesure : 0.9169475532556164\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class NaiveBayes(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classes = []\n",
    "        self.prioiri = []\n",
    "        self.vraissemblance = []\n",
    "        self.colonnes = 0\n",
    "        \n",
    "    # fonction d'entrainement\n",
    "    def entrainement(self,x, y):\n",
    "        \n",
    "        n_lignes = x.shape[0]\n",
    "        if len(y) != n_lignes :\n",
    "            raise Exception(\"la taille de 'y' n'es pas egale au nombre de ligne de 'x'\")\n",
    "        \n",
    "        # Calcul des probabilites a priori et conservations des noms de classes\n",
    "        self.colonnes = x.shape[1]\n",
    "        res = np.unique(y, return_counts=True)\n",
    "        self.prioiri = (res[1]/n_lignes)\n",
    "        self.classes = res[0]\n",
    "        \n",
    "        # Calcul des probabilites de vraissemblence et conservations d'attributs\n",
    "        attributs = []\n",
    "        for i in range(self.colonnes):\n",
    "            attributs.append(np.unique(x[:,i]).tolist())\n",
    "        \n",
    "        # pour chaque classe cj\n",
    "        for i in range(self.classes.shape[0]):\n",
    "        \n",
    "            # restriction du tableau de depart selon la classe\n",
    "            indices = np.where(y == self.classes[i])\n",
    "            data = x[indices][:]\n",
    "            \n",
    "            s = []\n",
    "            # pour chaque attribut\n",
    "            for j in range(self.colonnes):\n",
    "                \n",
    "                probabite = {}\n",
    "                # pour chaque valeur d'attributs\n",
    "                for val_atribut in attributs[j]:\n",
    "                    # occurence de l'attribut dans le sous tableau\n",
    "                    occur = len(np.where(data[:,j] == val_atribut)[0])\n",
    "                    probabite[val_atribut] = occur / data.shape[0]\n",
    "            \n",
    "                s.append(probabite)\n",
    "            self.vraissemblance.append(s)         \n",
    "    \n",
    "    # fonction d'inference \n",
    "    def inference(self, x):\n",
    "        if x.shape[1] != self.colonnes :\n",
    "            raise Exception(\"la donnee fourni n'es pas compatible avec le modele\")\n",
    "            \n",
    "        predict = []\n",
    "        # pour chaque ligne\n",
    "        for i in range(x.shape[0]):\n",
    "            \n",
    "            # on retrouve la classe maximisant la probabilite posteriori\n",
    "            p = self.prioiri.copy()\n",
    "            for j in range(self.classes.shape[0]):\n",
    "                \n",
    "                # pour tous les attributs\n",
    "                for k in range(x.shape[1]):\n",
    "                    try:\n",
    "                        val = x[i,k]\n",
    "                        p[j] *= self.vraissemblance[j][k][val]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    \n",
    "            # choisir un indice aleatoirement s'il y'a plusieurs choix\n",
    "            max_p = max(p)\n",
    "            indices = np.where(p == max_p)[0]\n",
    "            ind = indices[0]\n",
    "                \n",
    "            # ajout de la classe trouve\n",
    "            predict.append(self.classes[ind])\n",
    "        return predict\n",
    "    \n",
    "model = NaiveBayes()\n",
    "model.entrainement(X_train, y_train)\n",
    "\n",
    "pred = model.inference(X_test)\n",
    "matrice_confusion = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "print(\"matrice de confusion :\\n\" ,matrice_confusion)\n",
    "print(\"exactitude :\", exactitude(matrice_confusion))\n",
    "print(\"precision :\", precision(matrice_confusion))\n",
    "print(\"rappel :\", rappel(matrice_confusion))\n",
    "print(\"f-mesure :\", f_mesure(matrice_confusion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03d85422f651b7f3b8cfc404434b17496a20a36d5d6a328a4d5b29f706a68093"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
=======
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpExPiVJIRgg"
      },
      "source": [
        "`codage one hot`\n",
        "\n",
        "Vue pour utilisee la classification bayesienne, il est imperatif de transformer les textes de mail en des vecteurs numeriques leurs representant en s'appuyant sur l'ensemble des mots contenu dans ces derniers (appelé vocabulaire). \n",
        "\n",
        "Il existe plusieurs moyens de representation de texte, à l'instar du codage one hot dont le principe est : \" de part un mot du vocabulaire, si dans le texte ce mot est utilise on mettra `1` dans la position du vecteur correspondant a ce mot et `0` sinon \".\n",
        "\n",
        "pour le faire dans notre cas, nous avons choisi d'utiliser la classe `CountVectorizer` du module `sklearn.feature_extraction.text`, dont la particularité est qu'elle permet de conserver apres transformation des textes la matrice obtenu dans un objet de type `space matrix` permettant de mieux reduire la taille des donnees de la matrice en memoire lorsqu'il y'a grandement de valeur `0` inutile dans notre contexte \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYNWezT8IRgk",
        "outputId": "b2c0a1f1-dacd-4247-d42d-8248376fef33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dimension :  (5572, 8681)\n",
            " valeur de notre objet obtenu :    (0, 3550)\t1\n",
            "  (0, 8029)\t1\n",
            "  (0, 4350)\t1\n",
            "  (0, 5920)\t1\n",
            "  (0, 2327)\t1\n",
            "  (0, 1303)\t1\n",
            "  (0, 5537)\t1\n",
            "  (0, 4087)\t1\n",
            "  (0, 1751)\t1\n",
            "  (0, 3634)\t1\n",
            "  (0, 8488)\t1\n",
            "  (0, 4476)\t1\n",
            "  (0, 1749)\t1\n",
            "  (0, 2048)\t1\n",
            "  (0, 7645)\t1\n",
            "  (0, 3594)\t1\n",
            "  (0, 1069)\t1\n",
            "  (0, 8266)\t1\n",
            "  (1, 5504)\t1\n",
            "  (1, 4512)\t1\n",
            "  (1, 4318)\t1\n",
            "  (1, 8391)\t1\n",
            "  (1, 5533)\t1\n",
            "  (2, 4087)\t1\n",
            "  (2, 3358)\t1\n",
            "  :\t:\n",
            "  (5570, 4218)\t1\n",
            "  (5570, 8312)\t1\n",
            "  (5570, 1084)\t1\n",
            "  (5570, 4615)\t1\n",
            "  (5570, 7039)\t1\n",
            "  (5570, 3308)\t1\n",
            "  (5570, 7627)\t1\n",
            "  (5570, 1438)\t1\n",
            "  (5570, 5334)\t1\n",
            "  (5570, 2592)\t1\n",
            "  (5570, 8064)\t1\n",
            "  (5570, 1778)\t1\n",
            "  (5570, 7049)\t1\n",
            "  (5570, 2892)\t1\n",
            "  (5570, 3470)\t1\n",
            "  (5570, 1786)\t1\n",
            "  (5570, 3687)\t1\n",
            "  (5570, 4161)\t1\n",
            "  (5570, 903)\t1\n",
            "  (5570, 1546)\t1\n",
            "  (5571, 7756)\t1\n",
            "  (5571, 5244)\t1\n",
            "  (5571, 4225)\t2\n",
            "  (5571, 7885)\t1\n",
            "  (5571, 6505)\t1\n",
            " matrice y contenu : \n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer\n",
        "\n",
        "# on instancie le converteur de donnees texte de sklearn\n",
        "data_converter = CountVectorizer()\n",
        "\n",
        "# on realise la conversion\n",
        "spams_one_hot = data_converter.fit_transform(spams.text)\n",
        "\n",
        "print(\" dimension : \", spams_one_hot.shape)\n",
        "print(\" valeur de notre objet obtenu : \", spams_one_hot)\n",
        "print(\" matrice y contenu : \\n\", spams_one_hot.toarray())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA6lZJCCIRgm"
      },
      "source": [
        "la nous avons bien une \"sparse matrix\" contenant une matrice de 5572 lignes (qui est le nombre d'observation) et de 8681 colonnes (qui est le nombre de mots du vocabulaire). nous pouvons aussi nous rendre compte que cette matrice contient enormement de 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRS0CpsYIRgp"
      },
      "source": [
        "il faut noter qu'avoir un vocabulaire de 8681 mots est enorme et peut grandement impacter les performances de l'algorithme d'entrainement et donc il faudra minimiser le nombre de mots. \n",
        "\n",
        "Pour le faire nous pouvons:\n",
        "\n",
        "        - mettre tous les mots en miniscules \n",
        "fait par defaut lors de la conversion avec CountVectorizer\n",
        "                        \n",
        "        - recuperer uniquement les racines des mots \n",
        "fait par defaut grace au l'expression reguliere par defaut `r\"(?u)\\b\\w\\w+\\b\"`)\n",
        "    \n",
        "        - supprimer les mots d'utilité courante (par exemple 'il' , 'nous', ... etc) qui ont une forte probablite d'utilisation (frequence)\n",
        "egalement fait par defaut, cette frequence d'apparition est considere compris entre [0.7 .. 1]\n",
        "    \n",
        "        - donner un nombre de mots maximales\n",
        "induira forcement une baisse de performance du model\n",
        "\n",
        "Pour ce tutoriel nous definirons un nombre maximum de mots a 3000 (choix preferentiel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaNFE2AGIRgs",
        "outputId": "630d12dd-0d56-4abd-92fc-856c9ebd06a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dimension :  (5572, 3000)\n"
          ]
        }
      ],
      "source": [
        "# on instancie le converteur de donnees texte de sklearn\n",
        "data_converter = CountVectorizer(max_features=3000)\n",
        "\n",
        "# on realise la conversion\n",
        "spams_one_hot = data_converter.fit_transform(spams.text)\n",
        "\n",
        "print(\" dimension : \", spams_one_hot.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRf5fc4TIRgw"
      },
      "source": [
        "## phase d'entrainement et evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GP1H4JVIRgy"
      },
      "source": [
        "decoupage en partie de test et d'apprentissage homogene des donnes pretraitees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdYyN195IRgz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data, labels = spams_one_hot.toarray(), spams['class'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( data, labels, train_size=0.8, test_size=0.2, stratify= labels, random_state = 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO6wMkmVIRg1"
      },
      "source": [
        "entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW-bVHh4IRg3",
        "outputId": "b42e81d9-526e-4e97-cdbe-34f5b6ef1d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import  BernoulliNB\n",
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc1hdwcTIRg6"
      },
      "source": [
        "prediction et evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkTsG2JCIRg7",
        "outputId": "fd29241a-03db-4b8a-eba5-2445446c4414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1115,)\n",
            "(1115,)\n",
            "matrice de confusion :\n",
            " [[964   2]\n",
            " [ 14 135]]\n",
            "exactitude : 0.9856502242152466\n",
            "precision : 0.9855432657143284\n",
            "rappel : 0.9519849375408174\n",
            "f-mesure : 0.968473483563818\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(y_test.shape)\n",
        "print(predictions.shape)\n",
        "\n",
        "def exactitude(m):\n",
        "    result= 0\n",
        "    for i in range(m.shape[0]):\n",
        "        result += m[i,i]\n",
        "    return result/(sum(sum(m)))\n",
        "    \n",
        "def precision(m):\n",
        "    result=0\n",
        "    for i in range(m.shape[0]):\n",
        "        result += m[i,i]/sum(m[:,i])\n",
        "    return result/2   \n",
        "    \n",
        "def rappel(m):\n",
        "    result=0\n",
        "    for i in range(m.shape[0]):\n",
        "        result += m[i,i]/sum(m[i,:])\n",
        "    return result/2 \n",
        "def f_mesure(m):\n",
        "    r=p=0\n",
        "    for i in range(m.shape[0]):\n",
        "        r += m[i,i]/sum(m[i,:])\n",
        "        p += m[i,i]/sum(m[:,i])\n",
        "    r/=2\n",
        "    p/=2\n",
        "    return 2*r*p/(r+p) \n",
        "\n",
        "matrice_confusion = confusion_matrix(y_true=y_test, y_pred=predictions)\n",
        "print(\"matrice de confusion :\\n\" ,matrice_confusion)\n",
        "print(\"exactitude :\", exactitude(matrice_confusion))\n",
        "print(\"precision :\", precision(matrice_confusion))\n",
        "print(\"rappel :\", rappel(matrice_confusion))\n",
        "print(\"f-mesure :\", f_mesure(matrice_confusion))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwqLFE2aIRg-"
      },
      "source": [
        "malgres les valeurs de mettriques obtenu, il fautt noter que cette evaluation est basée sur les predictions faites sur les donnees de test pretraitées en meme temps que ceux de l'entrainnement.\n",
        "Ainsi pour avoir la certitude que le modele est si bon, on pourrait reprétraiter les données et les utilises pour les tests "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uWyOJWxIRg_",
        "outputId": "5dab953e-322c-41f4-efcf-9be58923a77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572,)\n",
            "(5572,)\n",
            "matrice de confusion :\n",
            " [[4815   10]\n",
            " [  63  684]]\n",
            "exactitude : 0.9868987796123474\n",
            "precision : 0.9863378244733456\n",
            "rappel : 0.956795055871153\n",
            "f-mesure : 0.971341860786683\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# repretraitement des donnees\n",
        "spams_one_hot = data_converter.transform(spams.text)\n",
        "data, labels = spams_one_hot.toarray(), spams['class'].values\n",
        "\n",
        "#predictions\n",
        "predictions = model.predict(data)\n",
        "\n",
        "print(labels.shape)\n",
        "print(predictions.shape)\n",
        "\n",
        "matrice_confusion = confusion_matrix(y_true=labels, y_pred=predictions)\n",
        "print(\"matrice de confusion :\\n\" ,matrice_confusion)\n",
        "print(\"exactitude :\", exactitude(matrice_confusion))\n",
        "print(\"precision :\", precision(matrice_confusion))\n",
        "print(\"rappel :\", rappel(matrice_confusion))\n",
        "print(\"f-mesure :\", f_mesure(matrice_confusion))\n"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "03d85422f651b7f3b8cfc404434b17496a20a36d5d6a328a4d5b29f706a68093"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "tp2.ipynb",
      "provenance": [],
      "toc_visible": true
    }
>>>>>>> e870ab0989bef8a31a4267cbe9b21b7c18bf694c
  },
  "nbformat": 4,
  "nbformat_minor": 0
}